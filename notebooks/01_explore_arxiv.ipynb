{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://export.arxiv.org/api/query?search_query=all:machine_learning&start=0&max_results=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the HTTP request to the arXiv API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='UTF-8'?>\n",
      "<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <id>https://arxiv.org/api/4ywPkJb26sH36879aU7XapznRfY</id>\n",
      "  <title>arXiv Query: search_query=all:machine_learning&amp;id_list=&amp;start=0&amp;max_results=1</title>\n",
      "  <updated>2026-02-11T16:48:57Z</updated>\n",
      "  <link href=\"https://arxiv.org/api/query?search_query=all:machine_learning&amp;start=0&amp;max_results=1&amp;id_list=\" type=\"application/atom+xml\"/>\n",
      "  <opensearch:itemsPerPage>1</opensearch:itemsPerPage>\n",
      "  <opensearch:totalResults>1</opensearch:totalResults>\n",
      "  <opensearch:startIndex>0</opensearch:startIndex>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2511.12129v1</id>\n",
      "    <title>A Practical Machine Learning Approach for Dynamic Stock Recommendation</title>\n",
      "    <updated>2025-11-15T09:32:03Z</updated>\n",
      "    <link href=\"https://arxiv.org/abs/2511.12129v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link href=\"https://arxiv.org/pdf/2511.12129v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n",
      "    <summary>Stock recommendation is vital to investment companies and investors. However, no single stock selection strategy will always win while analysts may not have enough time to check all S&amp;P 500 stocks (the Standard &amp; Poor's 500). In this paper, we propose a practical scheme that recommends stocks from S&amp;P 500 using machine learning. Our basic idea is to buy and hold the top 20% stocks dynamically. First, we select representative stock indicators with good explanatory power. Secondly, we take five frequently used machine learning methods, including linear regression, ridge regression, stepwise regression, random forest and generalized boosted regression, to model stock indicators and quarterly log-return in a rolling window. Thirdly, we choose the model with the lowest Mean Square Error in each period to rank stocks. Finally, we test the selected stocks by conducting portfolio allocation methods such as equally weighted, mean-variance, and minimum-variance. Our empirical results show that the proposed scheme outperforms the long-only strategy on the S&amp;P 500 index in terms of Sharpe ratio and cumulative returns. This work is fully open-sourced at \\href{https://github.com/AI4Finance-Foundation/Dynamic-Stock-Recommendation-Machine_Learning-Published-Paper-IEEE}{GitHub}.</summary>\n",
      "    <category term=\"q-fin.TR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"q-fin.CP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"q-fin.PM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <published>2025-11-15T09:32:03Z</published>\n",
      "    <arxiv:comment>Accepted by IEEE TrustCom/BigDataSE 2018. Supported by AI4Finance Foundation</arxiv:comment>\n",
      "    <arxiv:primary_category term=\"q-fin.TR\"/>\n",
      "    <author>\n",
      "      <name>Hongyang Yang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiao-Yang Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Qingwei Wu</name>\n",
      "    </author>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    data = response.text\n",
    "    print(data)\n",
    "else:\n",
    "    print(f\"Failed to retriev data. Status code :{response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = xmltodict.parse(data)\n",
    "json_data = json.dumps(data_dict, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"feed\": {\n",
      "        \"@xmlns:opensearch\": \"http://a9.com/-/spec/opensearch/1.1/\",\n",
      "        \"@xmlns:arxiv\": \"http://arxiv.org/schemas/atom\",\n",
      "        \"@xmlns\": \"http://www.w3.org/2005/Atom\",\n",
      "        \"id\": \"https://arxiv.org/api/4ywPkJb26sH36879aU7XapznRfY\",\n",
      "        \"title\": \"arXiv Query: search_query=all:machine_learning&id_list=&start=0&max_results=1\",\n",
      "        \"updated\": \"2026-02-11T16:48:57Z\",\n",
      "        \"link\": {\n",
      "            \"@href\": \"https://arxiv.org/api/query?search_query=all:machine_learning&start=0&max_results=1&id_list=\",\n",
      "            \"@type\": \"application/atom+xml\"\n",
      "        },\n",
      "        \"opensearch:itemsPerPage\": \"1\",\n",
      "        \"opensearch:totalResults\": \"1\",\n",
      "        \"opensearch:startIndex\": \"0\",\n",
      "        \"entry\": {\n",
      "            \"id\": \"http://arxiv.org/abs/2511.12129v1\",\n",
      "            \"title\": \"A Practical Machine Learning Approach for Dynamic Stock Recommendation\",\n",
      "            \"updated\": \"2025-11-15T09:32:03Z\",\n",
      "            \"link\": [\n",
      "                {\n",
      "                    \"@href\": \"https://arxiv.org/abs/2511.12129v1\",\n",
      "                    \"@rel\": \"alternate\",\n",
      "                    \"@type\": \"text/html\"\n",
      "                },\n",
      "                {\n",
      "                    \"@href\": \"https://arxiv.org/pdf/2511.12129v1\",\n",
      "                    \"@rel\": \"related\",\n",
      "                    \"@type\": \"application/pdf\",\n",
      "                    \"@title\": \"pdf\"\n",
      "                }\n",
      "            ],\n",
      "            \"summary\": \"Stock recommendation is vital to investment companies and investors. However, no single stock selection strategy will always win while analysts may not have enough time to check all S&P 500 stocks (the Standard & Poor's 500). In this paper, we propose a practical scheme that recommends stocks from S&P 500 using machine learning. Our basic idea is to buy and hold the top 20% stocks dynamically. First, we select representative stock indicators with good explanatory power. Secondly, we take five frequently used machine learning methods, including linear regression, ridge regression, stepwise regression, random forest and generalized boosted regression, to model stock indicators and quarterly log-return in a rolling window. Thirdly, we choose the model with the lowest Mean Square Error in each period to rank stocks. Finally, we test the selected stocks by conducting portfolio allocation methods such as equally weighted, mean-variance, and minimum-variance. Our empirical results show that the proposed scheme outperforms the long-only strategy on the S&P 500 index in terms of Sharpe ratio and cumulative returns. This work is fully open-sourced at \\\\href{https://github.com/AI4Finance-Foundation/Dynamic-Stock-Recommendation-Machine_Learning-Published-Paper-IEEE}{GitHub}.\",\n",
      "            \"category\": [\n",
      "                {\n",
      "                    \"@term\": \"q-fin.TR\",\n",
      "                    \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                },\n",
      "                {\n",
      "                    \"@term\": \"q-fin.CP\",\n",
      "                    \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                },\n",
      "                {\n",
      "                    \"@term\": \"q-fin.PM\",\n",
      "                    \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                }\n",
      "            ],\n",
      "            \"published\": \"2025-11-15T09:32:03Z\",\n",
      "            \"arxiv:comment\": \"Accepted by IEEE TrustCom/BigDataSE 2018. Supported by AI4Finance Foundation\",\n",
      "            \"arxiv:primary_category\": {\n",
      "                \"@term\": \"q-fin.TR\"\n",
      "            },\n",
      "            \"author\": [\n",
      "                {\n",
      "                    \"name\": \"Hongyang Yang\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Xiao-Yang Liu\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Qingwei Wu\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract important information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = data_dict['feed']['entry']['id']\n",
    "title = data_dict['feed']['entry']['title']\n",
    "updated = data_dict['feed']['entry']['updated']\n",
    "link = data_dict['feed']['entry']['link'][0]['@href']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: http://arxiv.org/abs/2511.12129v1\n",
      "Title: A Practical Machine Learning Approach for Dynamic Stock Recommendation\n",
      "Updated: 2025-11-15T09:32:03Z\n",
      "Link: https://arxiv.org/abs/2511.12129v1\n"
     ]
    }
   ],
   "source": [
    "print(f\"ID: {id}\")\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Updated: {updated}\")\n",
    "print(f\"Link: {link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handel multi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = \"https://export.arxiv.org/api/query?search_query=all:machine%learning&start=0&max_results=5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='UTF-8'?>\n",
      "<feed xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\" xmlns:arxiv=\"http://arxiv.org/schemas/atom\" xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <id>https://arxiv.org/api/C8UyhTgzZof91Y/9wDNtLizjw+U</id>\n",
      "  <title>arXiv Query: search_query=all:machine%learning&amp;id_list=&amp;start=0&amp;max_results=5</title>\n",
      "  <updated>2026-02-11T17:09:27Z</updated>\n",
      "  <link href=\"https://arxiv.org/api/query?search_query=all:machine%25learning&amp;start=0&amp;max_results=5&amp;id_list=\" type=\"application/atom+xml\"/>\n",
      "  <opensearch:itemsPerPage>5</opensearch:itemsPerPage>\n",
      "  <opensearch:totalResults>307278</opensearch:totalResults>\n",
      "  <opensearch:startIndex>0</opensearch:startIndex>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2306.04338v1</id>\n",
      "    <title>Changing Data Sources in the Age of Machine Learning for Official Statistics</title>\n",
      "    <updated>2023-06-07T11:08:12Z</updated>\n",
      "    <link href=\"https://arxiv.org/abs/2306.04338v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link href=\"https://arxiv.org/pdf/2306.04338v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n",
      "    <summary>Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.\n",
      "  This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse.</summary>\n",
      "    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <published>2023-06-07T11:08:12Z</published>\n",
      "    <arxiv:comment>Presented at UNECE Machine Learning for Official Statistics Workshop 2023</arxiv:comment>\n",
      "    <arxiv:primary_category term=\"stat.ML\"/>\n",
      "    <arxiv:journal_ref>UNECE Machine Learning for Official Statistics Workshop 2023</arxiv:journal_ref>\n",
      "    <author>\n",
      "      <name>Cedric De Boom</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Michael Reusens</name>\n",
      "    </author>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2302.08893v4</id>\n",
      "    <title>Active learning for data streams: a survey</title>\n",
      "    <updated>2023-11-29T21:07:15Z</updated>\n",
      "    <link href=\"https://arxiv.org/abs/2302.08893v4\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link href=\"https://arxiv.org/pdf/2302.08893v4\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n",
      "    <summary>Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online active learning, which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research.</summary>\n",
      "    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"stat.ME\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <published>2023-02-17T14:24:13Z</published>\n",
      "    <arxiv:comment>Published in Machine Learning (2023)</arxiv:comment>\n",
      "    <arxiv:primary_category term=\"stat.ML\"/>\n",
      "    <arxiv:journal_ref>Machine Learning (2023): 1-55</arxiv:journal_ref>\n",
      "    <author>\n",
      "      <name>Davide Cacciarelli</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Murat Kulahci</name>\n",
      "    </author>\n",
      "    <arxiv:doi>10.1007/s10994-023-06454-2</arxiv:doi>\n",
      "    <link rel=\"related\" href=\"https://doi.org/10.1007/s10994-023-06454-2\" title=\"doi\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/1705.05172v1</id>\n",
      "    <title>Emotion in Reinforcement Learning Agents and Robots: A Survey</title>\n",
      "    <updated>2017-05-15T11:49:56Z</updated>\n",
      "    <link href=\"https://arxiv.org/abs/1705.05172v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link href=\"https://arxiv.org/pdf/1705.05172v1\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n",
      "    <summary>This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.</summary>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.HC\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.RO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <published>2017-05-15T11:49:56Z</published>\n",
      "    <arxiv:comment>To be published in Machine Learning Journal</arxiv:comment>\n",
      "    <arxiv:primary_category term=\"cs.LG\"/>\n",
      "    <arxiv:journal_ref>Machine Learning 2017</arxiv:journal_ref>\n",
      "    <author>\n",
      "      <name>Thomas M. Moerland</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Joost Broekens</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Catholijn M. Jonker</name>\n",
      "    </author>\n",
      "    <arxiv:doi>10.1007/s10994-017-5666-0</arxiv:doi>\n",
      "    <link rel=\"related\" href=\"https://doi.org/10.1007/s10994-017-5666-0\" title=\"doi\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2201.12150v2</id>\n",
      "    <title>Learning Curves for Decision Making in Supervised Machine Learning: A Survey</title>\n",
      "    <updated>2025-01-28T14:39:26Z</updated>\n",
      "    <link href=\"https://arxiv.org/abs/2201.12150v2\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link href=\"https://arxiv.org/pdf/2201.12150v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n",
      "    <summary>Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework.</summary>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <published>2022-01-28T14:34:32Z</published>\n",
      "    <arxiv:comment>Accepted in Machine Learning Journal</arxiv:comment>\n",
      "    <arxiv:primary_category term=\"cs.LG\"/>\n",
      "    <arxiv:journal_ref>Machine Learning, Volume 113, pages 8371-8425 (2024)</arxiv:journal_ref>\n",
      "    <author>\n",
      "      <name>Felix Mohr</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jan N. van Rijn</name>\n",
      "    </author>\n",
      "    <arxiv:doi>10.1007/s10994-024-06619-7</arxiv:doi>\n",
      "    <link rel=\"related\" href=\"https://doi.org/10.1007/s10994-024-06619-7\" title=\"doi\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2304.02381v2</id>\n",
      "    <title>Physics-Inspired Interpretability Of Machine Learning Models</title>\n",
      "    <updated>2024-12-15T17:17:01Z</updated>\n",
      "    <link href=\"https://arxiv.org/abs/2304.02381v2\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link href=\"https://arxiv.org/pdf/2304.02381v2\" rel=\"related\" type=\"application/pdf\" title=\"pdf\"/>\n",
      "    <summary>The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable.</summary>\n",
      "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <published>2023-04-05T11:35:17Z</published>\n",
      "    <arxiv:comment>6 pages, 2 figures, ICLR 2023 Workshop on Physics for Machine Learning</arxiv:comment>\n",
      "    <arxiv:primary_category term=\"cs.LG\"/>\n",
      "    <arxiv:journal_ref>ICLR 2023 Workshop on Physics for Machine Learning</arxiv:journal_ref>\n",
      "    <author>\n",
      "      <name>Maximilian P Niroomand</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>David J Wales</name>\n",
      "    </author>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response2 = requests.get(URL2)\n",
    "if response2.status_code == 200:\n",
    "    data2 = response2.text\n",
    "    print(data2)    \n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response2.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict2 = xmltodict.parse(data2)\n",
    "json_data2 = json.dumps(data_dict2, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"feed\": {\n",
      "        \"@xmlns:opensearch\": \"http://a9.com/-/spec/opensearch/1.1/\",\n",
      "        \"@xmlns:arxiv\": \"http://arxiv.org/schemas/atom\",\n",
      "        \"@xmlns\": \"http://www.w3.org/2005/Atom\",\n",
      "        \"id\": \"https://arxiv.org/api/C8UyhTgzZof91Y/9wDNtLizjw+U\",\n",
      "        \"title\": \"arXiv Query: search_query=all:machine%learning&id_list=&start=0&max_results=5\",\n",
      "        \"updated\": \"2026-02-11T17:09:27Z\",\n",
      "        \"link\": {\n",
      "            \"@href\": \"https://arxiv.org/api/query?search_query=all:machine%25learning&start=0&max_results=5&id_list=\",\n",
      "            \"@type\": \"application/atom+xml\"\n",
      "        },\n",
      "        \"opensearch:itemsPerPage\": \"5\",\n",
      "        \"opensearch:totalResults\": \"307278\",\n",
      "        \"opensearch:startIndex\": \"0\",\n",
      "        \"entry\": [\n",
      "            {\n",
      "                \"id\": \"http://arxiv.org/abs/2306.04338v1\",\n",
      "                \"title\": \"Changing Data Sources in the Age of Machine Learning for Official Statistics\",\n",
      "                \"updated\": \"2023-06-07T11:08:12Z\",\n",
      "                \"link\": [\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/abs/2306.04338v1\",\n",
      "                        \"@rel\": \"alternate\",\n",
      "                        \"@type\": \"text/html\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/pdf/2306.04338v1\",\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@type\": \"application/pdf\",\n",
      "                        \"@title\": \"pdf\"\n",
      "                    }\n",
      "                ],\n",
      "                \"summary\": \"Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.\\n  This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse.\",\n",
      "                \"category\": [\n",
      "                    {\n",
      "                        \"@term\": \"stat.ML\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"cs.LG\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    }\n",
      "                ],\n",
      "                \"published\": \"2023-06-07T11:08:12Z\",\n",
      "                \"arxiv:comment\": \"Presented at UNECE Machine Learning for Official Statistics Workshop 2023\",\n",
      "                \"arxiv:primary_category\": {\n",
      "                    \"@term\": \"stat.ML\"\n",
      "                },\n",
      "                \"arxiv:journal_ref\": \"UNECE Machine Learning for Official Statistics Workshop 2023\",\n",
      "                \"author\": [\n",
      "                    {\n",
      "                        \"name\": \"Cedric De Boom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Michael Reusens\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"http://arxiv.org/abs/2302.08893v4\",\n",
      "                \"title\": \"Active learning for data streams: a survey\",\n",
      "                \"updated\": \"2023-11-29T21:07:15Z\",\n",
      "                \"link\": [\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/abs/2302.08893v4\",\n",
      "                        \"@rel\": \"alternate\",\n",
      "                        \"@type\": \"text/html\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/pdf/2302.08893v4\",\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@type\": \"application/pdf\",\n",
      "                        \"@title\": \"pdf\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@href\": \"https://doi.org/10.1007/s10994-023-06454-2\",\n",
      "                        \"@title\": \"doi\"\n",
      "                    }\n",
      "                ],\n",
      "                \"summary\": \"Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online active learning, which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research.\",\n",
      "                \"category\": [\n",
      "                    {\n",
      "                        \"@term\": \"stat.ML\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"cs.LG\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"stat.ME\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    }\n",
      "                ],\n",
      "                \"published\": \"2023-02-17T14:24:13Z\",\n",
      "                \"arxiv:comment\": \"Published in Machine Learning (2023)\",\n",
      "                \"arxiv:primary_category\": {\n",
      "                    \"@term\": \"stat.ML\"\n",
      "                },\n",
      "                \"arxiv:journal_ref\": \"Machine Learning (2023): 1-55\",\n",
      "                \"author\": [\n",
      "                    {\n",
      "                        \"name\": \"Davide Cacciarelli\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Murat Kulahci\"\n",
      "                    }\n",
      "                ],\n",
      "                \"arxiv:doi\": \"10.1007/s10994-023-06454-2\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"http://arxiv.org/abs/1705.05172v1\",\n",
      "                \"title\": \"Emotion in Reinforcement Learning Agents and Robots: A Survey\",\n",
      "                \"updated\": \"2017-05-15T11:49:56Z\",\n",
      "                \"link\": [\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/abs/1705.05172v1\",\n",
      "                        \"@rel\": \"alternate\",\n",
      "                        \"@type\": \"text/html\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/pdf/1705.05172v1\",\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@type\": \"application/pdf\",\n",
      "                        \"@title\": \"pdf\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@href\": \"https://doi.org/10.1007/s10994-017-5666-0\",\n",
      "                        \"@title\": \"doi\"\n",
      "                    }\n",
      "                ],\n",
      "                \"summary\": \"This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.\",\n",
      "                \"category\": [\n",
      "                    {\n",
      "                        \"@term\": \"cs.LG\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"cs.AI\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"cs.HC\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"cs.RO\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"stat.ML\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    }\n",
      "                ],\n",
      "                \"published\": \"2017-05-15T11:49:56Z\",\n",
      "                \"arxiv:comment\": \"To be published in Machine Learning Journal\",\n",
      "                \"arxiv:primary_category\": {\n",
      "                    \"@term\": \"cs.LG\"\n",
      "                },\n",
      "                \"arxiv:journal_ref\": \"Machine Learning 2017\",\n",
      "                \"author\": [\n",
      "                    {\n",
      "                        \"name\": \"Thomas M. Moerland\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Joost Broekens\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Catholijn M. Jonker\"\n",
      "                    }\n",
      "                ],\n",
      "                \"arxiv:doi\": \"10.1007/s10994-017-5666-0\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"http://arxiv.org/abs/2201.12150v2\",\n",
      "                \"title\": \"Learning Curves for Decision Making in Supervised Machine Learning: A Survey\",\n",
      "                \"updated\": \"2025-01-28T14:39:26Z\",\n",
      "                \"link\": [\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/abs/2201.12150v2\",\n",
      "                        \"@rel\": \"alternate\",\n",
      "                        \"@type\": \"text/html\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/pdf/2201.12150v2\",\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@type\": \"application/pdf\",\n",
      "                        \"@title\": \"pdf\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@href\": \"https://doi.org/10.1007/s10994-024-06619-7\",\n",
      "                        \"@title\": \"doi\"\n",
      "                    }\n",
      "                ],\n",
      "                \"summary\": \"Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework.\",\n",
      "                \"category\": {\n",
      "                    \"@term\": \"cs.LG\",\n",
      "                    \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                },\n",
      "                \"published\": \"2022-01-28T14:34:32Z\",\n",
      "                \"arxiv:comment\": \"Accepted in Machine Learning Journal\",\n",
      "                \"arxiv:primary_category\": {\n",
      "                    \"@term\": \"cs.LG\"\n",
      "                },\n",
      "                \"arxiv:journal_ref\": \"Machine Learning, Volume 113, pages 8371-8425 (2024)\",\n",
      "                \"author\": [\n",
      "                    {\n",
      "                        \"name\": \"Felix Mohr\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"Jan N. van Rijn\"\n",
      "                    }\n",
      "                ],\n",
      "                \"arxiv:doi\": \"10.1007/s10994-024-06619-7\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"http://arxiv.org/abs/2304.02381v2\",\n",
      "                \"title\": \"Physics-Inspired Interpretability Of Machine Learning Models\",\n",
      "                \"updated\": \"2024-12-15T17:17:01Z\",\n",
      "                \"link\": [\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/abs/2304.02381v2\",\n",
      "                        \"@rel\": \"alternate\",\n",
      "                        \"@type\": \"text/html\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@href\": \"https://arxiv.org/pdf/2304.02381v2\",\n",
      "                        \"@rel\": \"related\",\n",
      "                        \"@type\": \"application/pdf\",\n",
      "                        \"@title\": \"pdf\"\n",
      "                    }\n",
      "                ],\n",
      "                \"summary\": \"The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable.\",\n",
      "                \"category\": [\n",
      "                    {\n",
      "                        \"@term\": \"cs.LG\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"@term\": \"cs.AI\",\n",
      "                        \"@scheme\": \"http://arxiv.org/schemas/atom\"\n",
      "                    }\n",
      "                ],\n",
      "                \"published\": \"2023-04-05T11:35:17Z\",\n",
      "                \"arxiv:comment\": \"6 pages, 2 figures, ICLR 2023 Workshop on Physics for Machine Learning\",\n",
      "                \"arxiv:primary_category\": {\n",
      "                    \"@term\": \"cs.LG\"\n",
      "                },\n",
      "                \"arxiv:journal_ref\": \"ICLR 2023 Workshop on Physics for Machine Learning\",\n",
      "                \"author\": [\n",
      "                    {\n",
      "                        \"name\": \"Maximilian P Niroomand\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"name\": \"David J Wales\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: http://arxiv.org/abs/2306.04338v1\n",
      "Title: Changing Data Sources in the Age of Machine Learning for Official Statistics\n",
      "Updated: 2023-06-07T11:08:12Z\n",
      "Link: https://arxiv.org/abs/2306.04338v1\n",
      "----------------------------------------\n",
      "ID: http://arxiv.org/abs/2302.08893v4\n",
      "Title: Active learning for data streams: a survey\n",
      "Updated: 2023-11-29T21:07:15Z\n",
      "Link: https://arxiv.org/abs/2302.08893v4\n",
      "----------------------------------------\n",
      "ID: http://arxiv.org/abs/1705.05172v1\n",
      "Title: Emotion in Reinforcement Learning Agents and Robots: A Survey\n",
      "Updated: 2017-05-15T11:49:56Z\n",
      "Link: https://arxiv.org/abs/1705.05172v1\n",
      "----------------------------------------\n",
      "ID: http://arxiv.org/abs/2201.12150v2\n",
      "Title: Learning Curves for Decision Making in Supervised Machine Learning: A Survey\n",
      "Updated: 2025-01-28T14:39:26Z\n",
      "Link: https://arxiv.org/abs/2201.12150v2\n",
      "----------------------------------------\n",
      "ID: http://arxiv.org/abs/2304.02381v2\n",
      "Title: Physics-Inspired Interpretability Of Machine Learning Models\n",
      "Updated: 2024-12-15T17:17:01Z\n",
      "Link: https://arxiv.org/abs/2304.02381v2\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = data_dict2['feed']['entry']\n",
    "\n",
    "if isinstance(result, dict):\n",
    "    result = [result]  # convert to list\n",
    "\n",
    "for entry in result:\n",
    "    id = entry['id']\n",
    "    title = entry['title']\n",
    "    updated = entry['updated']\n",
    "    link = entry['link'][0]['@href']\n",
    "\n",
    "    print(f\"ID: {id}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Updated: {updated}\")\n",
    "    print(f\"Link: {link}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PDF link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Link: https://arxiv.org/pdf/2306.04338v1\n",
      "PDF Link: https://arxiv.org/pdf/2302.08893v4\n",
      "PDF Link: https://arxiv.org/pdf/1705.05172v1\n",
      "PDF Link: https://arxiv.org/pdf/2201.12150v2\n",
      "PDF Link: https://arxiv.org/pdf/2304.02381v2\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "for entry in result:\n",
    "    link = entry['link'][0]['@href'].replace('/abs/', '/pdf/')\n",
    "    links.append(link)\n",
    "    print(f\"PDF Link: {link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing Data Sources in the Age of Machine Learning for Official Statistics.pdf downloaded successfully\n",
      "Active learning for data streams: a survey.pdf downloaded successfully\n",
      "Emotion in Reinforcement Learning Agents and Robots: A Survey.pdf downloaded successfully\n",
      "Learning Curves for Decision Making in Supervised Machine Learning: A Survey.pdf downloaded successfully\n",
      "Physics-Inspired Interpretability Of Machine Learning Models.pdf downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for entry in result:\n",
    "\n",
    "    output_path = f\"data/{entry['title']}.pdf\"\n",
    "    link = entry['link'][0]['@href'].replace('/abs/', '/pdf/')\n",
    "\n",
    "    response = requests.get(link, stream=True, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "        print(f\"{entry['title']}.pdf downloaded successfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL3 = \"https://export.arxiv.org/api/query?search_query=all:electron&start=0&max_results=5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_arxiv_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "        data_dict = xmltodict.parse(data)\n",
    "        return data_dict['feed']['entry']\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf(entry):\n",
    "    output_path = f\"data/{entry['title']}.pdf\"\n",
    "    link = entry['link'][0]['@href'].replace('/abs/', '/pdf/')\n",
    "    response = requests.get(link, stream=True, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "        print(f\"{entry['title']}.pdf downloaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The electronic structure of cuprates from high energy spectroscopy.pdf downloaded successfully\n",
      "Surface effects on the electronic energy loss of charged particles entering a metal surface.pdf downloaded successfully\n",
      "A geometrical meaning to the electron mass from breakdown of Lorentz invariance.pdf downloaded successfully\n",
      "Ultrafast Electron Dynamics in the Topological Insulator Bi2Se3 Studied by Time-Resolved Photoemission Spectroscopy.pdf downloaded successfully\n",
      "Electronic and magnetic properties of the graphene densely decorated with 3d metallic adatoms.pdf downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "results = fetch_arxiv_data(URL3)\n",
    "if results:\n",
    "    if isinstance(results, dict):\n",
    "        results = [results]  # convert to list if only one entry\n",
    "    for entry in results:\n",
    "        save_pdf(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
