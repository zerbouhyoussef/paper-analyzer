{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompte = \"\"\"You are analyzing an academic research paper. Provide a structured summary:\n",
    "\n",
    "1. RESEARCH QUESTION: What problem does this paper address?\n",
    "2. METHODOLOGY: How did they approach it?\n",
    "3. DATA/MATERIALS: What did they use?\n",
    "4. KEY FINDINGS: What did they discover? (3-5 points)\n",
    "5. CONTRIBUTIONS: What's novel about this work?\n",
    "6. LIMITATIONS: What are the weaknesses or limitations?\n",
    "\n",
    "Be specific and use the paper's own terminology.\n",
    "\n",
    "Paper text: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_text = \"\"\n",
    "with open(\"data/output_PyPDF2.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    paper_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model = \"gpt-4.1-mini\",\n",
    "    input = prompte + paper_text,\n",
    "    temperature = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Structured Summary**\\n\\n1. **RESEARCH QUESTION**  \\n   The paper addresses the problem of how changes in external data sources impact the production of official statistics when using machine learning (ML). Specifically, it investigates the risks, liabilities, and uncertainties associated with changing data sources and their repercussions on the integrity, reliability, and neutrality of ML-driven official statistics.\\n\\n2. **METHODOLOGY**  \\n   The authors conduct a conceptual and analytical overview rather than empirical experimentation. They:  \\n   - Review the nature and challenges of using external data sources in ML for official statistics.  \\n   - Categorize and analyze types and causes of data source changes (technical, legal, ethical, ownership-related).  \\n   - Discuss the consequences of such changes on statistical production and ML model performance.  \\n   - Propose a checklist of risks and mitigation strategies based on literature and practical examples.  \\n   - Provide recommendations for statistical agencies to manage these challenges effectively.\\n\\n3. **DATA/MATERIALS**  \\n   The paper does not use original datasets but draws on:  \\n   - Existing literature and technical reports on ML and official statistics.  \\n   - Case examples such as the Twitter API changes.  \\n   - References to various data types (social media, administrative records, surveys) and ML methodologies (supervised, unsupervised learning).  \\n   - Regulatory frameworks (e.g., GDPR) and ethical considerations relevant to data sourcing.\\n\\n4. **KEY FINDINGS**  \\n   - **Types and Causes of Data Changes:** Changes in data types/schemas, sharing/collection technologies, concept drift, frequency interruptions, ownership changes, legal regulations, and ethical/public perception shifts all contribute to data source variability.  \\n   - **Consequences:** Changing data sources can cause concept drift, model staleness, bias, loss of neutrality, data unavailability, integration challenges, increased labor and costs, breaking changes, and degradation of quality metrics (timeliness, validity, accuracy, completeness).  \\n   - **Risks of External Data:** Unlike traditional controlled data (surveys, administrative records), external data sources expose statistical agencies to powerlessness and lack of control, increasing vulnerability.  \\n   - **Mitigation Strategies:** Risk analysis, continuous monitoring, diversification of data sources, building technical robustness (data normalization, validation, testing), and establishing legal agreements (SLAs) are critical to managing changing data sources.  \\n   - **Tradeoffs:** Mitigation requires significant resources, effort, and long-term planning; no single solution fits all cases.\\n\\n5. **CONTRIBUTIONS**  \\n   - Provides a comprehensive checklist and taxonomy of risks related to changing external data sources in ML for official statistics, covering technical, legal, ethical, and operational dimensions.  \\n   - Highlights the underexposed issue of data source change and its critical impact on ML-driven official statistics.  \\n   - Offers practical guidance and best practices for statistical agencies to maintain integrity, reliability, and neutrality despite data source volatility.  \\n   - Emphasizes the importance of data control and legal robustness in the era of external data dependency.  \\n   - Bridges the gap between ML technical challenges and official statistics production requirements.\\n\\n6. **LIMITATIONS**  \\n   - The paper is conceptual and does not provide empirical validation or quantitative evaluation of the proposed mitigation strategies.  \\n   - Recommendations are high-level and may lack detailed implementation guidance tailored to specific use cases or domains.  \\n   - The complexity and resource intensity of mitigation efforts may limit practical adoption, especially for smaller statistical agencies.  \\n   - The dynamic nature of data ecosystems and regulatory environments means that some risks and solutions may evolve rapidly beyond the scope of this paper.  \\n   - Does not deeply explore the tradeoffs between model interpretability and performance in the context of changing data sources, though it mentions related ethical concerns.\\n\\n---\\n\\nThis summary captures the essence of the paper’s problem framing, analytical approach, key insights, novel contributions, and acknowledged limitations as presented by the authors.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_llm_output(text) :\n",
    "\n",
    "    # Remove section headers like \"1. RESEARCH QUESTION\"\n",
    "    text = re.sub(r'\\n?\\d+\\.\\s+[A-Z/ ]+\\s*\\n', '\\n', text)\n",
    "\n",
    "    # Remove inline numbered list items\n",
    "    text = re.sub(r'\\n?\\d+\\.\\s+', ' ', text)\n",
    "\n",
    "    # Remove leftover markdown artifacts\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
    "    text = re.sub(r'#+\\s*', '', text)\n",
    "    text = re.sub(r'\\n?---\\n?', '\\n', text)\n",
    "\n",
    "    # Clean LaTeX remnants\n",
    "    text = re.sub(r'\\\\\\((.*?)\\\\\\)', r'\\1', text)\n",
    "    text = re.sub(r'\\\\approx', '≈', text)\n",
    "    text = re.sub(r'\\\\times', '×', text)\n",
    "\n",
    "    # Remove bullet dashes\n",
    "    text = re.sub(r'^\\s*-\\s+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Join wrapped lines into paragraphs\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "\n",
    "    # Normalize spacing\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_response = clean_llm_output(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Summary RESEARCH QUESTION The paper addresses the problem of how changes in external data sources impact the production of official statistics when using machine learning (ML). Specifically, it investigates the risks, liabilities, and uncertainties associated with changing data sources and their repercussions on the integrity, reliability, and neutrality of ML-driven official statistics. METHODOLOGY The authors conduct a conceptual and analytical overview rather than empirical experimentation. They: Review the nature and challenges of using external data sources in ML for official statistics. Categorize and analyze types and causes of data source changes (technical, legal, ethical, ownership-related). Discuss the consequences of such changes on statistical production and ML model performance. Propose a checklist of risks and mitigation strategies based on literature and practical examples. Provide recommendations for statistical agencies to manage these challenges effectively. DATA/MATERIALS The paper does not use original datasets but draws on: Existing literature and technical reports on ML and official statistics. Case examples such as the Twitter API changes. References to various data types (social media, administrative records, surveys) and ML methodologies (supervised, unsupervised learning). Regulatory frameworks (e.g., GDPR) and ethical considerations relevant to data sourcing. KEY FINDINGS Types and Causes of Data Changes: Changes in data types/schemas, sharing/collection technologies, concept drift, frequency interruptions, ownership changes, legal regulations, and ethical/public perception shifts all contribute to data source variability. Consequences: Changing data sources can cause concept drift, model staleness, bias, loss of neutrality, data unavailability, integration challenges, increased labor and costs, breaking changes, and degradation of quality metrics (timeliness, validity, accuracy, completeness). Risks of External Data: Unlike traditional controlled data (surveys, administrative records), external data sources expose statistical agencies to powerlessness and lack of control, increasing vulnerability. Mitigation Strategies: Risk analysis, continuous monitoring, diversification of data sources, building technical robustness (data normalization, validation, testing), and establishing legal agreements (SLAs) are critical to managing changing data sources. Tradeoffs: Mitigation requires significant resources, effort, and long-term planning; no single solution fits all cases. CONTRIBUTIONS Provides a comprehensive checklist and taxonomy of risks related to changing external data sources in ML for official statistics, covering technical, legal, ethical, and operational dimensions. Highlights the underexposed issue of data source change and its critical impact on ML-driven official statistics. Offers practical guidance and best practices for statistical agencies to maintain integrity, reliability, and neutrality despite data source volatility. Emphasizes the importance of data control and legal robustness in the era of external data dependency. Bridges the gap between ML technical challenges and official statistics production requirements. LIMITATIONS The paper is conceptual and does not provide empirical validation or quantitative evaluation of the proposed mitigation strategies. Recommendations are high-level and may lack detailed implementation guidance tailored to specific use cases or domains. The complexity and resource intensity of mitigation efforts may limit practical adoption, especially for smaller statistical agencies. The dynamic nature of data ecosystems and regulatory environments means that some risks and solutions may evolve rapidly beyond the scope of this paper. Does not deeply explore the tradeoffs between model interpretability and performance in the context of changing data sources, though it mentions related ethical concerns. This summary captures the essence of the paper’s problem framing, analytical approach, key insights, novel contributions, and acknowledged limitations as presented by the authors.\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Structured Summary RESEARCH QUESTION The paper addresses the problem of how changes in external data sources impact the production of official statistics when using machine learning (ML). Specifically, it investigates the risks, liabilities, and uncertainties associated with changing data sources and their repercussions on the integrity, reliability, and neutrality of ML-driven official statistics. METHODOLOGY The authors conduct a conceptual and analytical overview rather than empirical experimentation. They: Review the nature and challenges of using external data sources in ML for official statistics. Categorize and analyze types and causes of data source changes (technical, legal, ethical, ownership-related). Discuss the consequences of such changes on statistical production and ML model performance. Propose a checklist of risks and mitigation strategies based on literature and practical examples. Provide recommendations for statistical agencies to manage these challenges effectively. DATA/MATERIALS The paper does not use original datasets but draws on: Existing literature and technical reports on ML and official statistics. Case examples such as the Twitter API changes. References to various data types (social media, administrative records, surveys) and ML methodologies (supervised, unsupervised learning). Regulatory frameworks (e.g., GDPR) and ethical considerations relevant to data sourcing. KEY FINDINGS Types and Causes of Data Changes: Changes in data types/schemas, sharing/collection technologies, concept drift, frequency interruptions, ownership changes, legal regulations, and ethical/public perception shifts all contribute to data source variability. Consequences: Changing data sources can cause concept drift, model staleness, bias, loss of neutrality, data unavailability, integration challenges, increased labor and costs, breaking changes, and degradation of quality metrics (timeliness, validity, accuracy, completeness). Risks of External Data: Unlike traditional controlled data (surveys, administrative records), external data sources expose statistical agencies to powerlessness and lack of control, increasing vulnerability. Mitigation Strategies: Risk analysis, continuous monitoring, diversification of data sources, building technical robustness (data normalization, validation, testing), and establishing legal agreements (SLAs) are critical to managing changing data sources. Tradeoffs: Mitigation requires significant resources, effort, and long-term planning; no single solution fits all cases. CONTRIBUTIONS Provides a comprehensive checklist and taxonomy of risks related to changing external data sources in ML for official statistics, covering technical, legal, ethical, and operational dimensions. Highlights the underexposed issue of data source change and its critical impact on ML-driven official statistics. Offers practical guidance and best practices for statistical agencies to maintain integrity, reliability, and neutrality despite data source volatility. Emphasizes the importance of data control and legal robustness in the era of external data dependency. Bridges the gap between ML technical challenges and official statistics production requirements. LIMITATIONS The paper is conceptual and does not provide empirical validation or quantitative evaluation of the proposed mitigation strategies. Recommendations are high-level and may lack detailed implementation guidance tailored to specific use cases or domains. The complexity and resource intensity of mitigation efforts may limit practical adoption, especially for smaller statistical agencies. The dynamic nature of data ecosystems and regulatory environments means that some risks and solutions may evolve rapidly beyond the scope of this paper. Does not deeply explore the tradeoffs between model interpretability and performance in the context of changing data sources, though it mentions related ethical concerns. This summary captures the essence of the paper’s problem framing, analytical approach, key insights, novel contributions, and acknowledged limitations as presented by the authors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(cleaned_response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/structured_summary.txt\", \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
